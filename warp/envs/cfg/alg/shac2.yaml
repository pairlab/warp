name: shac2
num_envs: 128
params:
  network:
    actor: 
      _target_: shac.models.actor.ActorStochasticMLP # ActorDeterministicMLP
      device: ${general.device}
      cfg_network:
        actor_mlp:
          units: ${task.shac2.actor_mlp.units}
          activation: elu

    critic_name: q_network
    critic: 
      _target_: shac.models.critic.QCriticMLP
      cfg_network:
        critic_mlp:
          units: ${task.shac2.critic_mlp.units}
          activation: elu

  config:
    name: ${task.name}_${...name}
    actor_optimizer: ${..default_actor_opt}
    critic_optimizer: ${..default_critic_opt}
    lr_schedule: linear # ['constant', 'linear', 'adaptive']
    target_critic_alpha: ${resolve_default:0.4,${task.shac2.target_critic_alpha}}
    obs_rms: True
    ret_rms: False
    critic_iterations: 16
    critic_method: td-lambda # ['td-lambda', 'one-step']
    lam: ${task.shac2.lambda}
    num_batch: 4
    gamma: 0.99
    max_epochs: ${resolve_default:2000,${task.shac2.max_epochs}}
    steps_num: ${resolve_default:32,${task.shac2.steps_num}}
    grad_norm: 1.0
    truncate_grads: True
    contact_truncation: False
    save_interval: ${resolve_default:400,${task.shac2.save_interval}}
    early_stopping_patience: ${task.shac2.max_epochs}
    rew_scale: 1.0
    score_keys: ${resolve_default:[],${task.score_keys}}

    player:
      determenistic: True
      games_num: ${resolve_default:1,${task.player.games_num}}
      num_actors: ${resolve_default:1,${task.player.num_actors}}
      print_stats: True

  default_actor_opt:
    _target_: torch.optim.Adam
    lr: ${task.shac2.actor_lr} # adam
    betas: ${task.shac2.betas} # adam

  default_critic_opt:
    _target_: torch.optim.Adam
    lr: ${task.shac2.critic_lr} # adam
    betas: ${task.shac2.betas} # adam

  default_adaptive_scheduler:
    _target_: rl_games.common.schedulers.AdaptiveScheduler
    kl_threshold : 0.01

  default_linear_scheduler:
    _target_: rl_games.common.schedulers.LinearScheduler
    start_lr: ${..default_actor_opt.lr}
    min_lr: 1e-5
    max_steps: ${..config.max_epochs}
    apply_to_entropy: False
